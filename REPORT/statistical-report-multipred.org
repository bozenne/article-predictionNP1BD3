#+TITLE: Leveraging multimodal data to predict outcomes of antidepressant treatment
#+SUBTITLE: Preliminary results
#+Author: Brice Ozenne, Vibeke Dam

* Data

The data (n=98) we use has been provided by Emily Beaman. She processed
relevant data from the CIMBI database. In addition we compute:
- a "MR" biomarker as the average of the thickness of the left
  lateral, right lateral, left medial, and right medial orbitol
  frontal cortex.
- a "PET" biomarker by combining the log binding potential from
  neocortex, hippocampus, caudate, and putamen via a latent variable
  model (adjusted for age, gender, and injected mass). This was done
  in a leave-one-out fashion i.e. the biomarker for individual \(i\)
  was obtained by fitting the model on all but the i-th individual and
  estimating the latent variable for the \(i\)-th individual based on
  its log-binding in the 4 regions.
- a "cognition" biomarker was obtained via a k-means algorithm on
  various cognitive outcomes (no leave-one-out here). 
- the "outcomes" by computing the relative change in HAMD6 between week 8 (or 12) and baseline.
Individuals who had missing HAMD6 at both week 8 and 12 were excluded (n=13)

\bigskip

The corresponding R code is in the file =0-data-management.R= available on [[https://github.com/bozenne/article-predictionNP1BD3/code-data-analysis][Github]].

\clearpage

* Data analysis

After discussion with neuroscientist, we have identified 10 candidate
biomarkers[fn::fMRI is missing in the list] for predicting recovery after SSRI treatment:
- =MR_OFCthick=: thickness of the OFC brain region measured with MR.
- =HAMD17=: depression score at baseline.
- =low_hsCRP=: high sensitivity CRP (l levels of inflammation in the body).
- =lvpet=: summary of the brain log-PET binding.
- =cognitive_cluster=: summary of the cognition
- =EEG_vigilance=: EEG signal (vigilance slope B1 bl)
- =CATS_scoretotal=: ??
- =CAR_AUCi=: Difference between the cortisol value and the cortisol value at wake-up cumulated over an hour. 
- =neuroticism=: 

\bigskip
  
*Missing values*: to simplify the analysis, we will assume that
missing data occured completely at random. In particular, that it is
not related to the outcome (patient did not leave the study because
they fully recover or they were so seriously depressed that they could
not stay in the study).

\bigskip

*Association between recovery and biomarkers*[fn::how does the
recovery vary in average (i.e. at a population level) as a function of
the biomarkers]: to assess whether the biomarker were associated with
recovery we fitted a logistic regression with gender and age vs. a
logistic regression with gender and age plus all biomarkers (as
additive effects). A likelihood ratio test was used to compare the two
models, i.e. assess the assocation over all biomarkers. Wald tests
were used to test the association for each biomarker. P-value were
adjusted for multiple comparison (i.e. FWER control) using a max-test
adjustment. \newline This procedure was performed 4 times: using week
8 or week 12 as the outcome, using complete case analysis (excluding
CATS, CAR, and neuroticism as biomarkers) or using multiple imputation
(MI) to handle missing values. When using MI, the original data was
cloned 100 times. In each clone, missing values were imputed using
Fully Conditional Specification (FCS) implemented by the MICE
algorithm citep:van2011mice. This algorithm alternates between
learning the relationship between variables, using a linear regression
for continuous variables, logistic regression for binary variables,
and a a proportional odds model for categorical variables with all
variables (outcome, age, gender, biomarkers) as predictors (as
suggested in cite:moons2006using), and impute by sampling from the
resulting distributions (rougthly speaking, a noisy version of the
best prediction).

\clearpage

*Predictive value of the biomarkers*[fn::are the biomarkers useful to
 predict recovery for an individual]: to assess whether the biomarkers
 can be used to discriminate between patients who will recover and
 patients who won't, we tested whether the Area Under the Curve (AUC)
 of a logistic model with age, gender, and the biomarkers was greated
 than 0.5, and whether it was greater than a model with only age and
 gender. We also compared the performance with a random forest
 (default hyperparameters: mtry = 3, 500 trees, node size 1). The AUC
 was estimated via 10 fold cross-validation repeted 100 times. An AUC
 was computed over all folds of a given repetition and then averaged
 acrossed repetions. The p-value was computed via a permutation test
 (100 repetitions). \newline Calibration plot were also computed using
 the local polynomial regression fitting (loess). \newline Missing
 value was handled either using complete case analysis (excluding
 CATS, CAR, and neuroticism as biomarkers) or predicting the recovery
 probability for a given subject based on a logistic model containing
 all biomarkers for which the subject has available data.

\bigskip

The corresponding R code is in the file =1-prediction.R= available on
[[https://github.com/bozenne/article-predictionNP1BD3/code-data-analysis][Github]].
# @@latex:any arbitrary LaTeX code@@

\clearpage

* Results

** Descriptive statistics

#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
setwd("c:/Users/hpl802/Documents/Github/article-predictionNP1BD3/")
source(file.path(path.code,"1-prediction.R"))
#+END_SRC

The dataset contained 85 patients, 84 with the outcome at week 8 and
81 with the outcome at week 12. Some summary statistics are displayed
below:
#+BEGIN_SRC R :exports results :results output :session *R* :cache no
options(width = 90)
summary(dfWR.NP1[,.SD,.SDcols = c(name.predictor,"Y_w8","Y_w12")])
#+END_SRC

#+RESULTS:
#+begin_example
     sex          age         MR_OFCthick        HAMD17         hsCRP          
 male  :25   Min.   :18.24   Min.   :2.318   Min.   :18.00   Length:88         
 female:63   1st Qu.:22.19   1st Qu.:2.512   1st Qu.:20.00   Class :character  
             Median :24.02   Median :2.566   Median :22.00   Mode  :character  
             Mean   :27.11   Mean   :2.577   Mean   :22.78                     
             3rd Qu.:28.56   3rd Qu.:2.640   3rd Qu.:25.00                     
             Max.   :57.31   Max.   :2.889   Max.   :31.00                     
                                                                               
     lvpet          cognitive_cluster EEG_vigilance       CATS_scoretotal
 Min.   :-0.82582   Min.   :1.000     Min.   :-1.500000   Min.   : 0.00  
 1st Qu.:-0.49394   1st Qu.:1.000     1st Qu.: 0.000000   1st Qu.:16.00  
 Median :-0.42380   Median :2.000     Median : 0.000000   Median :23.00  
 Mean   :-0.43275   Mean   :1.884     Mean   :-0.005952   Mean   :30.36  
 3rd Qu.:-0.35715   3rd Qu.:3.000     3rd Qu.: 0.000000   3rd Qu.:42.00  
 Max.   :-0.09773   Max.   :3.000     Max.   : 1.500000   Max.   :81.00  
 NA's   :2          NA's   :2         NA's   :4           NA's   :11     
    CAR_AUCi        neuroticism       Y_w8           Y_w12        
 Min.   :-1070.3   Min.   : 67.0   Mode :logical   Mode :logical  
 1st Qu.:   79.1   1st Qu.:109.0   FALSE:37        FALSE:22       
 Median :  221.9   Median :119.0   TRUE :47        TRUE :59       
 Mean   :  181.3   Mean   :120.7   NA's :4         NA's :7        
 3rd Qu.:  381.1   3rd Qu.:134.0                                  
 Max.   :  768.9   Max.   :155.0                                  
 NA's   :19        NA's   :25
#+end_example

The dataset contained many missing values. The pattern of the missing
values is summarized on figure autoref:fig:missingPattern. 48 patients
had full data and the rest of the patients had between 1 and 4 missing
data (number of red boxes per line). CATS, CAR, and neuroticm had a
large number of missing data (11, 17, and 24) and this is why they
were excluded from some analyses.

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
dfW.mdpattern <- md.pattern(dfWR.NP1[,.SD,.SDcols = c(name.predictor,"Y_w4","Y_w8","Y_w12")], plot = FALSE)[,c(name.predictor,"Y_w4","Y_w8","Y_w12")]
rownames(dfW.mdpattern)[NROW(dfW.mdpattern)] <- "total"
dfL.mdpattern <- reshape2::melt(cbind(index = -(1:NROW(dfW.mdpattern)), n = rownames(dfW.mdpattern), as.data.frame(dfW.mdpattern)), id.vars = c("index","n"))
dfL.mdpattern$value.char <- factor(dfL.mdpattern$value, levels = 0:1, labels = c("missing","available"))
dfL.mdpattern$index.char <- as.factor(dfL.mdpattern$index)
dfL.mdpattern$variable <- gsub("Y_","HAMD6_",dfL.mdpattern$variable, fixed = TRUE)
neworder <- order(dfL.mdpattern[dfL.mdpattern$n=="total","value"],decreasing = TRUE)
dfL.mdpattern$variable2 <- factor(dfL.mdpattern$variable,
                                  levels = as.character(dfL.mdpattern[dfL.mdpattern$n=="total","variable"])[neworder],
                                  labels = paste0(as.character(dfL.mdpattern[dfL.mdpattern$n=="total","variable"]),"\n (missing=",dfL.mdpattern[dfL.mdpattern$n=="total","value"],")")[neworder]
                                  )

library(ggplot2)

gg0 <- ggplot(dfL.mdpattern[dfL.mdpattern$n!="total",], aes(x=variable2 ,y=index.char,fill=value.char)) + geom_tile(color = "gray", size = 1.1)
gg0 <- gg0 + labs(fill = "", x = "")
gg0 <- gg0 + scale_y_discrete("number of patients", labels = setNames(dfL.mdpattern$n[!duplicated(dfL.mdpattern$index.char)], dfL.mdpattern$index.char[!duplicated(dfL.mdpattern$index.char)]))
gg0 <- gg0 + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
gg0 <- gg0 + theme(text = element_text(size=15),
                   axis.line = element_line(size = 1.25),
                   axis.ticks = element_line(size = 2),
                   axis.ticks.length=unit(.25, "cm"))


dfgg <- dfL.mdpattern[dfL.mdpattern$n!="total",]
dfgg$index.char <- factor(dfgg$index.char, levels = dfgg$index.char[order(as.numeric(dfgg$n)[!duplicated(dfgg$index.char)], decreasing = TRUE)])
gg <- ggplot(dfgg, aes(x=index.char, y=variable2, fill=value.char)) + geom_tile(color = "gray", size = 2)
gg <- gg + labs(fill = "", y = "")
gg <- gg + scale_x_discrete("number of patients", labels = setNames(dfL.mdpattern$n[!duplicated(dfL.mdpattern$index.char)], dfL.mdpattern$index.char[!duplicated(dfL.mdpattern$index.char)]))
gg <- gg + theme(text = element_text(size=15),
                 axis.line = element_line(size = 1.25),
                 axis.ticks = element_line(size = 2),
                 axis.ticks.length=unit(.25, "cm"))
gg
## ggsave(gg, filename = file.path("REPORT","figures","gg-missingPattern.pdf"), width = 12)
#+END_SRC

#+RESULTS:

\clearpage

#+name: fig:missingPattern
#+ATTR_LaTeX: :width 0.9\textwidth :options trim={0 0 0 0} :placement [!h]
#+CAPTION: Missing data patterns
[[./figures/gg-missingPattern.pdf]]


** Association study (week 8)

*Complete case*: excluding CATS, CAR, and neuroticism, we fitted two
logistic regressions (one with and one without the biomarkers) on the
75 patients with complete data. This likelihood ratio test showed
evidence for an association between biomarkers and recovery:
#+BEGIN_SRC R :exports results :results output :session *R* :cache no
anova(e.glm0_ccw8, e.glm_ccw8, test  = "Chisq")
#+END_SRC

#+RESULTS:
#+begin_example
Analysis of Deviance Table

Model 1: Y_w8 ~ female + age
Model 2: Y_w8 ~ female + age + MR_OFCthick + HAMD17 + low_hsCRP + lvpet + 
    cognitive_cluster2 + cognitive_cluster3 + EEG_vigilance
  Resid. Df Resid. Dev Df Deviance Pr(>Chi)   
1        72    100.696                        
2        65     80.818  7   19.878  0.00584 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#+end_example

Looking at the biomarker specific effects, high vigilance appeared to
be associated with poor recovery: odd ratio 0.179 (unit?) adjusted
p-value of 0.047. There was also a similar trend for cognitive cluster
3: odd ratio 0.15, adjusted p-value of 0.07.
#+BEGIN_SRC R :exports results :results output :session *R* :cache no
library(multcomp)
set.seed(10)

cbind("estimate" = summary(e.glm_ccw8)$coef[,1],
      "std.error" = summary(e.glm_ccw8)$coef[,2],
      "odd ratio"= exp(summary(e.glm_ccw8)$coef[,1]),
      "p.value" = summary(e.glm_ccw8)$coef[,4],
      "adjusted p-value" = c(NA,NA,NA,summary(glht(e.glm_ccw8, linfct = paste0(names(coef(e.glm_ccw8))[-(1:3)],"=0")), test = adjusted("free"))$test$pvalues))
#+END_SRC

#+RESULTS:
#+begin_example
                      estimate  std.error    odd ratio     p.value adjusted p-value
(Intercept)         9.15328187 8.39872601 9.445388e+03 0.275782879               NA
female             -0.35932885 0.64097717 6.981447e-01 0.575073390               NA
age                 0.05471804 0.04216889 1.056243e+00 0.194427297               NA
MR_OFCthick        -5.84569691 3.18471343 2.892318e-03 0.066424416       0.23752311
HAMD17              0.16179531 0.09514669 1.175620e+00 0.089040138       0.24208663
low_hsCRP           1.46954263 0.72733733 4.347246e+00 0.043337596       0.19466776
lvpet              -2.04888723 2.23330861 1.288782e-01 0.358921367       0.41535424
cognitive_cluster2 -0.81977323 0.69278301 4.405315e-01 0.236688505       0.41535424
cognitive_cluster3 -1.89634154 0.75932143 1.501168e-01 0.012510207       0.06993304
EEG_vigilance      -1.72062639 0.63876369 1.789540e-01 0.007066751       0.04675833
#+end_example

*Multiple imputation*: as a sensitivity analysis, we now used all
patients and all biomarkers and use multiple imputations (100
datasets) to handle missing value. Results are rather similar to the
complete case analysis, with a slight tendency for stronger effects.
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(pool(e.glm_impw8))[,c(1,2,3,5:6)]
#+END_SRC

#+RESULTS:
#+begin_example
                 term      estimate    std.error       df     p.value
1         (Intercept)  4.1516290163 8.6252902526 68.91234 0.631805406
2           sexfemale -0.5825951700 0.6420666199 68.66383 0.367382059
3                 age  0.0754554026 0.0456848728 68.79669 0.103163672
4         MR_OFCthick -5.9114103612 3.0378756765 68.80810 0.055751906
5              HAMD17  0.1808561403 0.0925544076 68.24495 0.054794466
6            hsCRPlow  1.6868813295 0.7699177493 67.17518 0.031925680
7               lvpet -2.6139562643 2.3770155497 68.85573 0.275301586
8  cognitive_cluster2 -1.1511850446 0.7226909239 68.23190 0.115801761
9  cognitive_cluster3 -2.7674590923 0.8726252184 68.19986 0.002273849
10      EEG_vigilance -1.9950780957 0.6945417890 68.76199 0.005411043
11    CATS_scoretotal -0.0001481392 0.0153985265 68.98892 0.992351959
12           CAR_AUCi  0.0007498367 0.0009340191 66.90661 0.424929161
13        neuroticism  0.0351547075 0.0211703226 68.99083 0.101339384
#+end_example

\bigskip

** Association study (week 12)

*Complete case*: excluding CATS, CAR, and neuroticism, we fitted two
logistic regressions (one with and one without the biomarkers) on the
72 patients with complete data. This likelihood ratio test showed no
clear evidence for an association between biomarkers and recovery:
#+BEGIN_SRC R :exports results :results output :session *R* :cache no
anova(e.glm0_ccw12, e.glm_ccw12, test  = "Chisq")
#+END_SRC

#+RESULTS:
: Analysis of Deviance Table
: 
: Model 1: Y_w12 ~ female + age
: Model 2: Y_w12 ~ female + age + MR_OFCthick + HAMD17 + low_hsCRP + lvpet + 
:     cognitive_cluster2 + cognitive_cluster3 + EEG_vigilance
:   Resid. Df Resid. Dev Df Deviance Pr(>Chi)
: 1        69     76.256                     
: 2        62     64.376  7    11.88   0.1046

This was confirmed when looking at the biomarker specific effects. We
can also see that the biomarkers for which with have most evidence
against the null (=MR_OFCthick= and =cognitive_cluster2=) differ from
week 8
#+BEGIN_SRC R :exports results :results output :session *R* :cache no
library(multcomp)
set.seed(10)

cbind("estimate" = summary(e.glm_ccw12)$coef[,1],
      "std.error" = summary(e.glm_ccw12)$coef[,2],
      "odd ratio"= exp(summary(e.glm_ccw12)$coef[,1]),
      "p.value" = summary(e.glm_ccw12)$coef[,4],
      "adjusted p-value" = c(NA,NA,NA,summary(glht(e.glm_ccw12, linfct = paste0(names(coef(e.glm_ccw12))[-(1:3)],"=0")), test = adjusted("free"))$test$pvalues))
#+END_SRC

#+RESULTS:
#+begin_example
                     estimate  std.error    odd ratio    p.value adjusted p-value
(Intercept)        15.1377108 9.66268612 3.751667e+06 0.11720467               NA
female             -0.1631019 0.71162765 8.495046e-01 0.81871691               NA
age                 0.1239538 0.07958311 1.131964e+00 0.11934255               NA
MR_OFCthick        -8.2502682 3.58368566 2.611885e-04 0.02132536        0.1342289
HAMD17              0.1706117 0.10751351 1.186030e+00 0.11253840        0.4384615
low_hsCRP           1.0809026 0.83834457 2.947339e+00 0.19728347        0.5786588
lvpet              -0.5703845 2.60457709 5.653080e-01 0.82665539        0.9698902
cognitive_cluster2 -1.4448166 0.79614533 2.357893e-01 0.06956004        0.3344590
cognitive_cluster3 -0.8051151 0.88884433 4.470365e-01 0.36504179        0.7385351
EEG_vigilance      -0.0668419 0.60067967 9.353431e-01 0.91139660        0.9698902
#+end_example

*Multiple imputation*: as a sensitivity analysis, we now used all
patients and all biomarkers and use multiple imputations (100
datasets) to handle missing value. Results are rather similar to the
complete case analysis, but with a stronger evidence for an assocation
between OFC thickness and recovery. Note that cognition and CATS are
bordeline significant without adjustment for multiple comparisons.
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(pool(e.glm_impw12))[,c(1,2,3,5:6)]
#+END_SRC

#+RESULTS:
#+begin_example
                 term     estimate   std.error       df     p.value
1         (Intercept) 16.760516575 9.890355948 65.99623 0.094859430
2           sexfemale -0.898638556 0.731432568 65.79797 0.223597826
3                 age  0.115967103 0.075427653 66.00500 0.128960677
4         MR_OFCthick -9.520173723 3.499858676 65.92820 0.008334242
5              HAMD17  0.141151055 0.103171990 65.81972 0.175928909
6            hsCRPlow  1.004339184 0.857512761 65.03615 0.245782198
7               lvpet -0.643880653 2.660297543 65.99493 0.809504882
8  cognitive_cluster2 -1.906920071 0.887507143 65.52557 0.035364314
9  cognitive_cluster3 -1.725228423 0.949783976 65.71480 0.073863526
10      EEG_vigilance -0.382219479 0.630217817 66.01354 0.546270922
11    CATS_scoretotal  0.037284123 0.020188426 66.02463 0.069257123
12           CAR_AUCi  0.001358667 0.001228576 65.78712 0.272803070
13        neuroticism  0.017883788 0.023653524 65.95409 0.452297597
#+end_example

** Predictive value (week 8)

*Complete case*: excluding CATS, CAR, and neuroticism, we assessed the
predictive performance of two logistic regressions (one with
=glm_ccw8= and one without the biomarkers =glm0_ccw8=) as well as a
random forest model (=rf_ccw8=) on the 75 patients with complete data:
#+BEGIN_SRC R :exports results :results output :session *R* :cache no
options(width = 100)
ePerf.ccw8[,1:4]
#+END_SRC

#+RESULTS:
#+begin_example
     method metric     model   estimate
1  internal    auc glm0_ccw8 0.62769010
2  internal    auc  glm_ccw8 0.81133429
3  internal    auc   rf_ccw8 1.00000000
4  internal  brier glm0_ccw8 0.23870239
5  internal  brier  glm_ccw8 0.17485453
6  internal  brier   rf_ccw8 0.09276568
7        cv    auc glm0_ccw8 0.52305595
8        cv    auc  glm_ccw8 0.67530846
9        cv    auc   rf_ccw8 0.55341822
10       cv  brier glm0_ccw8 0.25887838
11       cv  brier  glm_ccw8 0.23932881
12       cv  brier   rf_ccw8 0.25372824
#+end_example

After cross-validation, we observe that both the AUC and brier score
of the random forest (with biomarkers) are similar to the logistic
regression without biomarkers. This indicates poor predictive ability
of the random forest that will not be considered further. The logistic
model with biomarker has a higher AUC (i.e., better discrimination)
and lower brier score (i.e., smaller discrepancy between prediction
and observed outcome) compared to the logistic model without
biomarkers. The permutation test confirmed that the logistic model
with biomarkers was informative (p=0.02 for the AUC and p=0.01 for the
brier score \Warning @@latex:\textcolor{red}{to re-run with more
permutations}@@) while there was no clear evidence with the logistic
model without covariates (p=0.11 for the AUC and p=0.27 for the brier
score). This difference between the predictions from the models (after
cross validation) is illustrated in autoref:fig:predW8, as well as
the corresponding ROC autoref:fig:rocW8 and calibration curves
autoref:fig:caliW8.

\bigskip

Note that the average AUC estimated by the permutation test was 0.5,
supporting that the proposed cross-validation procedure is unbiased
(under the null).

\clearpage

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
ggsave(ggHist_w8 + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW8-hist.pdf"), width = 12, height = 6)
ggsave(ggHist2_w8 + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW8-hist2.pdf"), width = 12, height = 6)
ggsave(ggDens_w8  + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW8-dens.pdf"), width = 12, height = 6)
ggsave(ggCali_w8  + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW8-cali.pdf"), width = 12, height = 6)
ggsave(ggROC_w8  + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW8-roc.pdf"), width = 12, height = 6)
#+END_SRC

#+RESULTS:
: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
: `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'
: + `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

#+name: fig:predW8
#+ATTR_LaTeX: :width 1\textwidth :options trim={0 0 0 0} :placement [!h]
#+CAPTION: Distribution of the predicted probability of recovery according to the actual recovery for the various predictive models for week 8.
[[./figures/gg-perfW8-hist2.pdf]]

#+name: fig:rocW8
#+ATTR_LaTeX: :width 1\textwidth :options trim={0 0 0 0} :placement [!h]
#+CAPTION: Roc curve associated to the cross-validated predictions for the various models (thick lines) for week 8.
#+CAPTION: It is obtained by applying a smoother (lowess) on the 100 ROC curve obtain for each model and each of the 100 repetitions of the 10 fold cross validations (thin lines). 
[[./figures/gg-perfW8-roc.pdf]]

\clearpage

#+name: fig:caliW8
#+ATTR_LaTeX: :width 1\textwidth :options trim={0 0 0 0} :placement [!h]
#+CAPTION: Calibration curve associated to the cross-validated predictions for the various models (thick lines) for week 8. 
[[./figures/gg-perfW8-cali.pdf]]

\bigskip

*Full data*: as a sensitivity analysis, we now used all patients and
all biomarkers and modified the cross-validation procedure to handle
missing data. We obtain slightly different results, but still in favor
of the logistic model with biomarkers. The difference in AUC between
the logistic models is similar to previously (about +0.1) but now the
brier score is worse (+0.4 instead of 0.3) indicating poor
calibration.

#+BEGIN_SRC R :exports results :results output :session *R* :cache no
ePerf.w8[,1:4]
#+END_SRC

#+RESULTS:
:      method metric   model  estimate
: 1: internal    auc glm0_w8 0.5991949
: 2: internal    auc  glm_w8 0.8878666
: 3: internal  brier glm0_w8 0.2409137
: 4: internal  brier  glm_w8 0.1432597
: 5:       cv    auc glm0_w8 0.5574226
: 6:       cv    auc  glm_w8 0.6542563
: 7:       cv  brier glm0_w8 0.2581057
: 8:       cv  brier  glm_w8 0.3015577


\clearpage

** Predictive value (week 12)

*Complete case*: excluding CATS, CAR, and neuroticism, we assessed the
predictive performance of two logistic regressions (one with
=glm_ccw12= and one without the biomarkers =glm0_ccw12=) as well as a
random forest model (=rf_ccw12=) on the 72 patients with complete data:
#+BEGIN_SRC R :exports results :results output :session *R* :cache no
options(width = 100)
ePerf.ccw12[,1:4]
#+END_SRC

#+RESULTS:
#+begin_example
     method metric      model   estimate
1  internal    auc glm0_ccw12 0.66037736
2  internal    auc  glm_ccw12 0.79443893
3  internal    auc   rf_ccw12 1.00000000
4  internal  brier glm0_ccw12 0.18160078
5  internal  brier  glm_ccw12 0.14937617
6  internal  brier   rf_ccw12 0.05981177
7        cv    auc glm0_ccw12 0.57554121
8        cv    auc  glm_ccw12 0.60582920
9        cv    auc   rf_ccw12 0.76768620
10       cv  brier glm0_ccw12 0.19544784
11       cv  brier  glm_ccw12 0.21388319
12       cv  brier   rf_ccw12 0.16378866
#+end_example

After cross-validation, we observe that both the AUC and brier score
of the logistic regression with biomarkers are similar to the logistic
regression without biomarkers. This time it the random forest approach
that shows a higher AUC (i.e., better discrimination) and lower brier
score (i.e., smaller discrepancy between prediction and observed
outcome) compared to the logistic model without biomarkers. The
permutation test confirmed that the logistic model with biomarkers was
informative (p=0.01 for the AUC and p=0.01 for the brier score
\Warning @@latex:\textcolor{red}{to re-run with more permutations}@@) while
there was no clear evidence for the other logistic models (p>0.1 for
the AUC and brier score). This difference between the predictions from
the models (after cross validation) is illustrated in
autoref:fig:predW12, as well as the corresponding ROC
autoref:fig:rocW12 and calibration curves autoref:fig:caliW12.

\bigskip

Note that the average AUC estimated by the permutation test was 0.5,
supporting that the proposed cross-validation procedure is unbiased
(under the null).

\clearpage

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
ggsave(ggHist_w12 + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm"))b,
       filename = file.path("REPORT","figures","gg-perfW12-hist.pdf"), width = 12, height = 6)
ggsave(ggHist2_w12 + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW12-hist2.pdf"), width = 12, height = 6)
ggsave(ggDens_w12  + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW12-dens.pdf"), width = 12, height = 6)
ggsave(ggCali_w12  + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW12-cali.pdf"), width = 12, height = 6)
ggsave(ggROC_w12  + theme(text = element_text(size=20), axis.line = element_line(size = 1.25), axis.ticks = element_line(size = 2), axis.ticks.length=unit(.25, "cm")),
       filename = file.path("REPORT","figures","gg-perfW12-roc.pdf"), width = 12, height = 6)
#+END_SRC

#+RESULTS:
: `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
: `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'
: `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

#+name: fig:predW12
#+ATTR_LaTeX: :width 1\textwidth :options trim={0 0 0 0} :placement [!h]
#+CAPTION: Distribution of the predicted probability of recovery according to the actual recovery for the various predictive models for week 12.
[[./figures/gg-perfW12-hist2.pdf]]

#+name: fig:rocW12
#+ATTR_LaTeX: :width 1\textwidth :options trim={0 0 0 0} :placement [!h]
#+CAPTION: Roc curve associated to the cross-validated predictions for the various models (thick lines) for week 12.
#+CAPTION: It is obtained by applying a smoother (lowess) on the 100 ROC curve obtain for each model and each of the 100 repetitions of the 10 fold cross validations (thin lines). 
[[./figures/gg-perfW12-roc.pdf]]


\clearpage

#+name: fig:caliW12
#+ATTR_LaTeX: :width 1\textwidth :options trim={0 0 0 0} :placement [!h]
#+CAPTION: Calibration curve associated to the cross-validated predictions for the various models (thick lines) for week 12. 
[[./figures/gg-perfW12-cali.pdf]]


*Full data*: as a sensitivity analysis, we now used all patients and
all biomarkers and modified the cross-validation procedure to handle
missing data. The results are in line with the complete case, with
worse performances when adding the biomarkers.

#+BEGIN_SRC R :exports results :results output :session *R* :cache no
ePerf.w12[,1:4]
#+END_SRC

#+RESULTS:
:      method metric    model  estimate
: 1: internal    auc glm0_w12 0.6502311
: 2: internal    auc  glm_w12 0.8936826
: 3: internal  brier glm0_w12 0.1855812
: 4: internal  brier  glm_w12 0.1172801
: 5:       cv    auc glm0_w12 0.6017917
: 6:       cv    auc  glm_w12 0.5762885
: 7:       cv  brier glm0_w12 0.2181458
: 8:       cv  brier  glm_w12 0.2679212

\clearpage

* Conclusion

There is evidence that some biomarkers (EEG, to a lesser extend
cognition) are predictive of recovery at week 8. The corresponding
gain in AUC was about +0.1 with a small improvement in brier
score. These results were not seen at week 12 and the overall
predictive performance was not great though (AUC of about 0.6 and
brier score >0.2).

\bigskip

There was no evidence for non-linear effect or interaction between
biomarkers (as assessed via a random forest model) probably due to the
limited sample size.

\bigskip

Generally the results where robust to how missing data were handled
  (complete case or multiple imputation). Effects had a slight
  tendency to be stronger when not using complete case. The only
  exception is for the brier score at w8 which became worse compared
  to the complete case.  \bigskip


* References
#+LaTeX: \begingroup
#+LaTeX: \renewcommand{\section}[2]{}
bibliographystyle:apalike
[[bibliography:bibliography.bib]]
# help: https://gking.harvard.edu/files/natnotes2.pdf
#+LaTeX: \endgroup


* CONFIG :noexport:
# #+LaTeX_HEADER:\affil{Department of Biostatistics, University of Copenhagen, Copenhagen, Denmark}
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+LaTeX_CLASS_OPTIONS: [12pt]
#+OPTIONS:   title:t author:t toc:nil todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t
#+LATEX_HEADER: %
#+LATEX_HEADER: %%%% specifications %%%%
#+LATEX_HEADER: %
** Latex command
#+LATEX_HEADER: \usepackage{ifthen}
#+LATEX_HEADER: \usepackage{xifthen}
#+LATEX_HEADER: \usepackage{xargs}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \newcommand\Rlogo{\textbf{\textsf{R}}\xspace} % 
** Notations
** Code
# Documentation at https://org-babel.readthedocs.io/en/latest/header-args/#results
# :tangle (yes/no/filename) extract source code with org-babel-tangle-file, see http://orgmode.org/manual/Extracting-source-code.html 
# :cache (yes/no)
# :eval (yes/no/never)
# :results (value/output/silent/graphics/raw/latex)
# :export (code/results/none/both)
#+PROPERTY: header-args :session *R* :tangle yes :cache no ## extra argument need to be on the same line as :session *R*
# Code display:
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}
# ## change font size input
# ## #+ATTR_LATEX: :options basicstyle=\ttfamily\scriptsize
# ## change font size output
# ## \RecustomVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\tiny,formatcom = {\color[rgb]{0.5,0,0}}}
** Display 
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\renewcommand{\baselinestretch}{1.1}
#+LATEX_HEADER:\geometry{top=1cm}
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
# ## valid and cross symbols
#+LaTeX_HEADER: \RequirePackage{pifont}
#+LaTeX_HEADER: \RequirePackage{relsize}
#+LaTeX_HEADER: \newcommand{\Cross}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{56}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\Valid}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{52}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\CrossR}{ \textcolor{red}{\Cross} }
#+LaTeX_HEADER: \newcommand{\ValidV}{ \textcolor{green}{\Valid} }
# ## warning symbol
#+LaTeX_HEADER: \usepackage{stackengine}
#+LaTeX_HEADER: \usepackage{scalerel}
#+LaTeX_HEADER: \newcommand\Warning[1][3ex]{%
#+LaTeX_HEADER:   \renewcommand\stacktype{L}%
#+LaTeX_HEADER:   \scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
#+LaTeX_HEADER:   \xspace
#+LaTeX_HEADER: }
# # change the color of the links
#+LaTeX_HEADER: \hypersetup{
#+LaTeX_HEADER:  citecolor=[rgb]{0,0.5,0},
#+LaTeX_HEADER:  urlcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER:  linkcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER: }
** Image
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
#+LATEX_HEADER: \RequirePackage{capt-of} % 
#+LATEX_HEADER: \RequirePackage{caption} % newlines in graphics
** List
#+LATEX_HEADER: \RequirePackage{enumitem} % to be able to convert .eps to .pdf image files
** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}
** Math
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)
# ## lemma
# #+LaTeX_HEADER: \RequirePackage{amsthm}
# #+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
# #+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
*** Template for shortcut
#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }
*** Shortcuts
**** Probability
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}
**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}
#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}
#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}
#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\partial #2^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 
**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
