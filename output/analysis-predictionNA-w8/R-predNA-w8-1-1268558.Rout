
R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ### analysis-predictionNA-w8.R --- 
> ##----------------------------------------------------------------------
> ## Author: Brice Ozenne
> ## Created: mar  4 2022 (09:16) 
> ## Version: 
> ## Last-Updated: apr 21 2022 (16:03) 
> ##           By: Brice Ozenne
> ##     Update #: 57
> ##----------------------------------------------------------------------
> ## 
> ### Commentary: 
> ## 
> ### Change Log:
> ##----------------------------------------------------------------------
> ## 
> ### Code:
> 
> ## * Parameters
> n.resampling <- 100 ## 10000
> fold.size <- 0.1
> fold.repetition <- 50
> 
> iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_ID"))
> n.iter_sim <- as.numeric(Sys.getenv("SLURM_ARRAY_TASK_COUNT"))
> if(is.na(iter_sim)){iter_sim <- 1}
> if(is.na(n.iter_sim)){n.iter_sim <- 10}
> 
> vec.resampling <- (1+n.resampling*(iter_sim-1)):(n.resampling*iter_sim)
> cat("iteration ",iter_sim," over ",n.iter_sim,"\n", sep = "")
iteration 1 over 10
> cat("vec.repetition:\n")
vec.repetition:
> print(vec.resampling)
  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18
 [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36
 [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54
 [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72
 [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
 [91]  91  92  93  94  95  96  97  98  99 100
> cat("\n")

> 
> ## * Path
> if(system("whoami",intern=TRUE)=="hpl802"){
+     ## nothing: on the server
+     ## cd ucph/hdir/SundKonsolidering_BioStatHome/Cluster/BrainDrug-WP3/
+     ## source("code-data-analysis/analysis-predictionNA-w8.R")
+ }else if(system("whoami",intern=TRUE)=="unicph\\hpl802"){
+     setwd("c:/Users/hpl802/Documents/Github/article-predictionNP1BD3/")
+ }else{ ## 
+     setwd("Vibeke put your path here")
+ }
NULL
> path.code <- "./code-data-analysis"
> path.output <- "./output/"
> if(dir.exists(path.output)==FALSE){
+     dir.create(path.output)
+ }
> if(dir.exists(file.path(path.output,"analysis-predictionNA-w8"))==FALSE){
+     dir.create(file.path(path.output,"analysis-predictionNA-w8"))
+ }
> 
> path.results <- "./results/"
> if(dir.exists(path.results)==FALSE){
+     dir.create(path.results)
+ }
> if(dir.exists(file.path(path.results,"analysis-predictionNA-w8"))==FALSE){
+     dir.create(file.path(path.results,"analysis-predictionNA-w8"))
+ }
> 
> ## * Packages and function
> library(data.table)
> setDTthreads(1)
> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:stats’:

    cov, smooth, var

> library(ranger)
> library(splines)
> library(BuyseTest)
Loading required package: Rcpp
BuyseTest version 2.3.12

Attaching package: ‘BuyseTest’

The following object is masked from ‘package:pROC’:

    auc

> library(mice)

Attaching package: ‘mice’

The following object is masked from ‘package:stats’:

    filter

The following objects are masked from ‘package:base’:

    cbind, rbind

> ## devtools::install_github("NightingaleHealth/ggforestplot")
> 
> ## * Load data
> source(file.path(path.code,"0-data-management.R"))
Data management 

> 
> name.predictor <- c("sex","age","MR_OFCthick","HAMD17","hsCRP","lvpet","cognitive_cluster","EEG_vigilance","CATS_scoretotal","CAR_AUCi","neuroticism")
> nameT.predictor <- c("MR_OFCthick","HAMD17","hsCRP","lvpet","cognitive_cluster","EEG_vigilance","CATS_scoretotal","CAR_AUCi","neuroticism")
> nameR.predictor <- c("female","age","MR_OFCthick","HAMD17","low_hsCRP","lvpet","cognitive_cluster2","cognitive_cluster3","EEG_vigilance")
> nameRT.predictor <- c("MR_OFCthick","HAMD17","low_hsCRP","lvpet","cognitive_cluster2","cognitive_cluster3","EEG_vigilance")
> 
> ## * Missing values
> 
> dfWR.NP1_w8 <- dfWR.NP1[rowSums(is.na(dfWR.NP1[,.SD,.SDcols = c("Y_w8")]))==0,]
> ## butils::DIM(dfWR.NP1_w8)
> ## [1] 87 36
> 
> ## ** week 8
> set.seed(10)
> 
> ## *** fit models
> e.glm0_impw8 <- glm(Y_w8 ~ female + age, family = binomial(link = "logit"), data = dfWR.NP1_w8)
> ## e.glm_impw8 <- miss.glm(Y_w8 ~ female + age + MR_OFCthick + HAMD17 + low_hsCRP + lvpet + cognitive_cluster2 + cognitive_cluster3 + EEG_vigilance + CATS_scoretotal + CAR_AUCi + neuroticism, data = dfWR.NP1_w8,
> ##                  control = list(print_iter = FALSE, tol_em = 1e-5, ll_obs_cal = FALSE))
> e.glm_impw8 <- glm(Y_w8 ~ female + age + MR_OFCthick + HAMD17 + low_hsCRP + lvpet + cognitive_cluster2 + cognitive_cluster3 + EEG_vigilance + CATS_scoretotal + CAR_AUCi + neuroticism,
+                    family = binomial(link = "logit"), data = dfWR.NP1_w8)
> e.ranger_impw8 <- ranger(formula = Y_w8 ~ female + age + MR_OFCthick + HAMD17 + low_hsCRP + lvpet + cognitive_cluster2 + cognitive_cluster3 + EEG_vigilance + CATS_scoretotal + CAR_AUCi + neuroticism,
+                          data = na.omit(dfWR.NP1_w8), probability = TRUE)
> 
> ## e.glm0_impw8 <- glm(Y_w8 ~ female + age, family = binomial(link = "logit"), data = dfWR.NP1_w8)
> ## e.glm_impw8 <- glm(Y_w8 ~ female + age + MR_OFCthick + HAMD17 + low_hsCRP + lvpet + cognitive_cluster2 + cognitive_cluster3 + EEG_vigilance,
> ##                    family = binomial(link = "logit"), data = dfWR.NP1_w8)
> ## e.ranger_impw8 <- ranger(formula = Y_w8 ~ female + age + MR_OFCthick + HAMD17 + low_hsCRP + lvpet + cognitive_cluster2 + cognitive_cluster3 + EEG_vigilance,
> ##                          data = na.omit(dfWR.NP1_w8), probability = TRUE)
> 
> ## *** assess performance
> if(iter_sim==1){
+     ePerf.impw8.IF <- performance(list(glm0_impw8 = e.glm0_impw8, glm_impw8 = e.glm_impw8, rf_impw8 = e.ranger_impw8), data = dfWR.NP1_w8,
+                                   fold.repetition = fold.repetition, fold.balance = TRUE, fold.size = fold.size,
+                                   individual.fit = TRUE, impute = "mean",
+                                   conf.level = 0.95, seed = 10)
+     saveRDS(ePerf.impw8.IF, file = file.path(path.results,"perf-imp-week8-IF.rds"))
+     ePerf.impw8.IF
+ }
The training set seems to differ in size between models: 88, 50, 1. 

    Assessment of the predictive performance of 3 models

- Prediction: internal
              10 folds cross-validation repeated 50 times 
  |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   2%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |=======                                                               |  10%  |                                                                              |========                                                              |  12%  |                                                                              |==========                                                            |  14%  |                                                                              |===========                                                           |  16%  |                                                                              |=============                                                         |  18%  |                                                                              |==============                                                        |  20%  |                                                                              |===============                                                       |  22%  |                                                                              |=================                                                     |  24%  |                                                                              |==================                                                    |  26%  |                                                                              |====================                                                  |  28%  |                                                                              |=====================                                                 |  30%  |                                                                              |======================                                                |  32%  |                                                                              |========================                                              |  34%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  38%  |                                                                              |============================                                          |  40%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |================================                                      |  46%  |                                                                              |==================================                                    |  48%  |                                                                              |===================================                                   |  50%  |                                                                              |====================================                                  |  52%  |                                                                              |======================================                                |  54%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |==========================================                            |  60%  |                                                                              |===========================================                           |  62%  |                                                                              |=============================================                         |  64%  |                                                                              |==============================================                        |  66%  |                                                                              |================================================                      |  68%  |                                                                              |=================================================                     |  70%  |                                                                              |==================================================                    |  72%  |                                                                              |====================================================                  |  74%  |                                                                              |=====================================================                 |  76%  |                                                                              |=======================================================               |  78%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  82%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  88%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |===================================================================   |  96%  |                                                                              |===================================================================== |  98%  |                                                                              |======================================================================| 100%
- Performance: internal(done) CV(done)
     method metric      model estimate      se  lower upper p.value
1  internal    auc glm0_impw8   0.6156 0.06058 0.4858 0.722  0.0785
2  internal    auc  glm_impw8   0.7786 0.05356 0.6513 0.864  <0.001
3  internal    auc   rf_impw8   1.0000 0.00000 1.0000 1.000  <0.001
4  internal  brier glm0_impw8   0.2408 0.00968 0.2225 0.261        
5  internal  brier  glm_impw8   0.1921 0.02044 0.1559 0.237        
6  internal  brier   rf_impw8   0.0923 0.00513 0.0828 0.103        
7        cv    auc glm0_impw8   0.5490 0.05917 0.4262 0.656  0.4203
8        cv    auc  glm_impw8   0.6209 0.05866 0.4952 0.724  0.0588
9        cv    auc   rf_impw8   0.4784 0.05860 0.3602 0.587  0.7104
10       cv  brier glm0_impw8   0.2533 0.01134 0.2320 0.277        
11       cv  brier  glm_impw8   0.2585 0.02515 0.2136 0.313        
12       cv  brier   rf_impw8   0.2693 0.01395 0.2433 0.298        
   p.value_comp
1              
2       0.01970
3       < 0.001
4              
5       0.00808
6       < 0.001
7              
8       0.32741
9       0.00615
10             
11      0.81810
12      0.59046
> ##      method metric     model estimate      se  lower upper p.value p.value_comp
> ## 1  internal    auc glm0_ccw8   0.6156 0.06058 0.4858 0.722  0.0785             
> ## 2  internal    auc glm_impw8   0.7786 0.05356 0.6513 0.864  <0.001      0.01970
> ## 3  internal    auc  rf_impw8   1.0000 0.00000 1.0000 1.000  <0.001      < 0.001
> ## 4  internal  brier glm0_ccw8   0.2408 0.00968 0.2225 0.261                     
> ## 5  internal  brier glm_impw8   0.1921 0.02044 0.1559 0.237              0.00808
> ## 6  internal  brier  rf_impw8   0.0915 0.00541 0.0815 0.103              < 0.001
> ## 7        cv    auc glm0_ccw8   0.5497 0.06068 0.4236 0.659  0.4255             
> ## 8        cv    auc glm_impw8   0.6213 0.06037 0.4916 0.727  0.0656      0.34590
> ## 9        cv    auc  rf_impw8   0.4750 0.06030 0.3535 0.587  0.6751      0.00605
> ## 10       cv  brier glm0_ccw8   0.2535 0.01141 0.2321 0.277                     
> ## 11       cv  brier glm_impw8   0.2575 0.02522 0.2125 0.312              0.85815
> ## 12       cv  brier  rf_impw8   0.2702 0.01431 0.2435 0.300              0.52571
> 
> ePerf.impw8.perm <- performanceResample(list(glm0_impw8 = e.glm0_impw8, glm_impw8 = e.glm_impw8, rf_impw8 = e.ranger_impw8), data = dfWR.NP1_w8,
+                                         fold.repetition = fold.repetition, fold.balance = TRUE, fold.size = fold.size,
+                                         individual.fit = TRUE, impute = "mean",
+                                         type.resampling = "permutation", n.resampling = vec.resampling, seed = 10,
+                                         filename = file.path(path.results,"analysis-predictionNA-w8",paste0("iter",iter_sim,"-tempo")))
                                                                                                     > saveRDS(ePerf.impw8.perm, file = file.path(path.results,"analysis-predictionNA-w8",paste0("iter",iter_sim,"-final.rds")))
> ePerf.impw8.perm
     method metric      model estimate resample se.resample p.value
1  internal    auc glm0_impw8   0.6156   0.5662     0.04260  0.1485
2  internal    auc  glm_impw8   0.7786   0.7001     0.04548  0.0792
3  internal    auc   rf_impw8   1.0000   0.9999     0.00032  0.8812
4        cv    auc glm0_impw8   0.5490   0.4601     0.08276  0.1386
5        cv    auc  glm_impw8   0.6209   0.4784     0.08549  0.0693
6        cv    auc   rf_impw8   0.4784   0.4875     0.08066  0.5545
7  internal  brier glm0_impw8   0.2408   0.2422     0.00610  0.2574
8  internal  brier  glm_impw8   0.1921   0.2156     0.01427  0.0792
9  internal  brier   rf_impw8   0.0923   0.0897     0.00579  0.6634
10       cv  brier glm0_impw8   0.2533   0.2548     0.00684  0.2772
11       cv  brier  glm_impw8   0.2585   0.2955     0.01882  0.0792
12       cv  brier   rf_impw8   0.2693   0.2658     0.01568  0.5545
   p.value_comp
1              
2        0.2178
3        0.9307
4              
5        0.4356
6        0.0792
7              
8        0.0594
9        0.9604
10             
11       0.9802
12       0.8713
> 
> ## * sessionInfo
> sessionInfo()
R version 4.1.2 (2021-11-01)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Red Hat Enterprise Linux 8.5 (Ootpa)

Matrix products: default
BLAS:   /opt/software/R/4.1.2/lib64/R/lib/libRblas.so
LAPACK: /opt/software/R/4.1.2/lib64/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
[1] lava_1.6.10       pbapply_1.5-0     mice_3.14.0       BuyseTest_2.3.12 
[5] Rcpp_1.0.8.3      ranger_0.13.1     pROC_1.18.0       data.table_1.14.2

loaded via a namespace (and not attached):
 [1] pillar_1.7.0       compiler_4.1.2     plyr_1.8.6         tools_4.1.2       
 [5] digest_0.6.29      lifecycle_1.0.1    tibble_3.1.6       gtable_0.3.0      
 [9] lattice_0.20-45    pkgconfig_2.0.3    rlang_1.0.2        Matrix_1.3-4      
[13] cli_3.2.0          parallel_4.1.2     SparseM_1.81       prodlim_2019.11.13
[17] withr_2.5.0        dplyr_1.0.8        MatrixModels_0.5-0 generics_0.1.2    
[21] vctrs_0.4.1        globals_0.14.0     stats4_4.1.2       grid_4.1.2        
[25] tidyselect_1.1.2   glue_1.6.2         listenv_0.8.0      R6_2.5.1          
[29] future.apply_1.8.1 fansi_1.0.3        parallelly_1.31.0  survival_3.2-13   
[33] tidyr_1.2.0        ggplot2_3.3.5      purrr_0.3.4        magrittr_2.0.3    
[37] backports_1.4.1    scales_1.2.0       codetools_0.2-18   ellipsis_0.3.2    
[41] future_1.24.0      colorspace_2.0-3   utf8_1.2.2         munsell_0.5.0     
[45] broom_0.7.12       crayon_1.5.1      
> 
> ## * Bonus
> if(FALSE){
+ 
+     xxx <- misaem::miss.glm(Y_w8 ~ female + age + MR_OFCthick + HAMD17 + low_hsCRP + lvpet + cognitive_cluster2 + cognitive_cluster3 + EEG_vigilance + CATS_scoretotal + CAR_AUCi + neuroticism, data = dfWR.NP1_w8,
+                             control = list(print_iter = FALSE, tol_em = 1e-5, ll_obs_cal = FALSE))
+ 
+ 
+     ePerf.impw8.bis <- performance(list(glm0_impw8 = e.glm0_impw8, glm_impw8 = xxx, rf_impw8 = e.ranger_impw8), data = dfWR.NP1_w8,
+                                    individual.fit = TRUE,
+                                    fold.number = 1, fold.size = 0.1, seed = 10)
+ 
+     ePerf.impw8.bis <- performance(list(glm0_impw8 = e.glm0_impw8, glm_impw8 = e.glm_impw8, rf_impw8 = e.ranger_impw8), data = dfWR.NP1_w8,
+                                    individual.fit = TRUE,
+                                    fold.number = 1, fold.size = 0.1, seed = 10)
+ 
+ 
+     ePerf.impw8.bis <- performance(list(glm2_impw8 = xxx, rf_impw8 = e.ranger_impw8), data = dfWR.NP1_w8,
+                                    individual.fit = TRUE,
+                                    fold.number = 1, fold.size = 0.1, seed = 10)
+ 
+ 
+     
+     for(iSplit in 1:10){ ## iSplit <- 3
+         test1 <- prediction[index[,"split"]==iSplit,"glm0_impw8"]
+         GS1 <- predict(update(e.glm0_impw8, data = dfWR.NP1_w8[index[index[,"split"]!=iSplit,"observation"],]),
+                        newdata = dfWR.NP1_w8[index[index[,"split"]==iSplit,"observation"],],
+                        type = "response")
+         print(range(test1-GS1))
+         ## test - dfWR.NP1_w8[index[index[,"split"]==iSplit,"observation"], Y_w8]
+ 
+     }
+ 
+     dataSplit <- dfWR.NP1_w8[index[index[,"split"]==iSplit,"observation"],]
+     GS2 <- NULL
+     for(iData in 1:NROW(dataSplit)){ ## iData <- 1
+         test.NA <- unlist(lapply(as.list(dataSplit[iData,.SD, .SDcols = all.vars(formula(e.glm_impw8))]), is.na))
+         rm.var <- names(which(test.NA))
+ 
+         fff <- formula(e.glm_impw8)
+         if(length(rm.var)>0){
+             fff <- update(fff, paste0(".~.-", paste0(rm.var, collapse = "-")))
+         }
+ 
+ 
+         
+         xxx <- miss.glm(fff, data = dfWR.NP1_w8[index[index[,"split"]!=iSplit,"observation"],],
+                         control = list(print_iter = FALSE, tol_em = 1e-5, ll_obs_cal = FALSE))
+         lava::expit(as.double(model.matrix(fff, dataSplit[iData,]) %*% coef(xxx)))
+         
+         
+         GS2 <- c(GS2,predict(update(e.glm_impw8, data = dfWR.NP1_w8[index[index[,"split"]!=iSplit,"observation"],],
+                                   formula = fff),
+                            newdata = dataSplit[iData,],
+                            type = "response"))
+     }
+     test2 <- prediction[index[,"split"]==iSplit,"glm_impw8"]
+     print(range(GS2 - test2))
+     ## test2 - dfWR.NP1_w8[index[index[,"split"]==iSplit,"observation"], Y_w8]
+     mean((test1 - dfWR.NP1_w8[index[index[,"split"]==iSplit,"observation"], Y_w8])^2)
+     mean((test2 - dfWR.NP1_w8[index[index[,"split"]==iSplit,"observation"], Y_w8])^2)
+ }
> 
> ##----------------------------------------------------------------------
> ### analysis-predictionNA-w8.R ends here
> 
> proc.time()
    user   system  elapsed 
27129.03 31080.03 56137.21 
